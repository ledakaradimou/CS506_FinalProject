{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, HtmlElement found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a1429751bc1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0minput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'restaurants.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0mscraped_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0mscraped_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a1429751bc1b>\u001b[0m in \u001b[0;36mparse\u001b[0;34m(input_file)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mreview_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_review_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mraw_review_count\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mhotel_rating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_rating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mraw_rating\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mofficial_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_official_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mraw_official_description\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;31m#        details = ' '.join(' '.join(raw_details).split()) if raw_details else None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mlatitude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_latitude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mraw_latitude\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, HtmlElement found"
     ]
    }
   ],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def parse(input_file):\n",
    "    restaurants = []\n",
    "    for line in input_file:\n",
    "        url = line\n",
    "        response = requests.get(url).text\n",
    "        parser = html.fromstring(response)\n",
    "\t\n",
    "        XPATH_RATING = '//div[@id=\"ratingFilter\"]//ul//li'\n",
    "\n",
    "        XPATH_TRAVELER = '//div[@class=\"col segment extraWidth\"]//ul//li'\n",
    "        XPATH_TIME = '//div[@class=\"col season extraWidth\"]//ul/li'\n",
    "        XPATH_LANGUAGE = '//div[@class=\"col language extraWidth\"]//ul/li'\n",
    "#        XPATH_DETAILS = '//div[contains(@class,\"details_tab\")]//div[contains(@class, \"table_section\")]//text()'\n",
    "        XPATH_NAME = '//h1[@property=\"name\"]//text()'\n",
    "        XPATH_HOTEL_RATING = '//span[@property=\"ratingValue\"]//@content'\n",
    "        XPATH_REVIEWS = '//a[@property=\"reviewCount\"]/@content'\n",
    "        XPATH_RANK = '//div[@class=\"slim_ranking\"]//text()'\n",
    "#         XPATH_OFFICIAL_DESCRIPTION = '//div[contains(@class,\"additional_info\")]//span[contains(@class,\"tabs_descriptive_text\")]//text()'\n",
    "#         XPATH_OFFICIAL_DESCRIPTION = '//div[@class=\"additional_info\"]//div'\n",
    "        XPATH_LATITUDE = '//div[@class=\"mapContainer\"]//@data-lat'\n",
    "        XPATH_LONGITUDE = '//div[@class=\"mapContainer\"]//@data-lng'\n",
    "                                        \n",
    "        ratings = parser.xpath(XPATH_RATING)\n",
    "        travelers = parser.xpath(XPATH_TRAVELER)\n",
    "        times = parser.xpath(XPATH_TIME)\n",
    "        languages = parser.xpath(XPATH_LANGUAGE)\n",
    "\t\n",
    "        raw_name = parser.xpath(XPATH_NAME)\n",
    "        raw_rank = parser.xpath(XPATH_RANK)\n",
    "        raw_review_count = parser.xpath(XPATH_REVIEWS)\n",
    "        raw_rating = parser.xpath(XPATH_HOTEL_RATING)\n",
    "#         raw_official_description = parser.xpath(XPATH_OFFICIAL_DESCRIPTION)\n",
    "#        raw_details = parser.xpath(XPATH_DETAILS)\n",
    "        raw_latitude = parser.xpath(XPATH_LATITUDE)\n",
    "        raw_longitude = parser.xpath(XPATH_LONGITUDE)\n",
    "\t\t\t\t\t\n",
    "        name = ''.join(raw_name).strip() if raw_name else None\n",
    "        rank = ''.join(raw_rank).strip() if raw_rank else None\n",
    "        review_count = ''.join(raw_review_count).strip() if raw_review_count else None\n",
    "        hotel_rating = ''.join(raw_rating).strip() if raw_rating else None\n",
    "#         official_description = ' '.join(' '.join(raw_official_description).split()) if raw_official_description else None\n",
    "#        details = ' '.join(' '.join(raw_details).split()) if raw_details else None\n",
    "        latitude = ' '.join(' '.join(raw_latitude).split()) if raw_latitude else None  \n",
    "        longitude = ' '.join(' '.join(raw_longitude).split()) if raw_longitude else None \n",
    "\n",
    "        ratings_dict = OrderedDict()\n",
    "        for rating in ratings:\n",
    "            XPATH_RATING_KEY = './/div[@class=\"row_label\"]//text()'\n",
    "            XPATH_RATING_VALUE = './/span[@class=\"row_bar\"]/following-sibling::span//text()'\n",
    "            raw_rating_key = rating.xpath(XPATH_RATING_KEY)\n",
    "            raw_rating_value = rating.xpath(XPATH_RATING_VALUE)\n",
    "            cleaned_rating_key = ''.join(raw_rating_key).replace('\\n','')\n",
    "            cleaned_rating_value = ''.join(raw_rating_value).replace('\\n','')\n",
    "            ratings_dict.update({cleaned_rating_key:cleaned_rating_value})\n",
    "    \n",
    "        travelers_list = [] \n",
    "        for traveler in travelers:\n",
    "            XPATH_TRAVELER_TYPE = './/label//text()'\n",
    "            XPATH_TRAVELER_COUNT = './/span//text()'\n",
    "            raw_traveler_type = traveler.xpath(XPATH_TRAVELER_TYPE)\n",
    "            raw_traveler_count = traveler.xpath(XPATH_TRAVELER_COUNT)\n",
    "            cleaned_traveler_type = ''.join(raw_traveler_type).replace('\\n','').split(' ')\n",
    "            cleaned_traveler_type = cleaned_traveler_type[0]\n",
    "            cleaned_traveler_count = ''.join(raw_traveler_count).replace('\\n','')\n",
    "            travelers_list.append((cleaned_traveler_type,cleaned_traveler_count))\n",
    "        \n",
    "        times_list = []\n",
    "        for time in times:\n",
    "            XPATH_TIME_TYPE = './/label//text()'\n",
    "            XPATH_TIME_COUNT = './/span//text()'\n",
    "            raw_time_type = time.xpath(XPATH_TIME_TYPE)\n",
    "            raw_time_count = time.xpath(XPATH_TIME_COUNT)\n",
    "            cleaned_time_type = ''.join(raw_time_type).replace('\\n','').split(' ')\n",
    "            cleaned_time_type = cleaned_time_type[0]\n",
    "            cleaned_time_count = ''.join(raw_time_count).replace('\\n','')\n",
    "            times_list.append((cleaned_time_type, cleaned_time_count))\n",
    "        \n",
    "        language_list = []\n",
    "        for language in languages:\n",
    "            XPATH_LANGUAGE_TYPE = './/label//text()'\n",
    "            XPATH_LANGUAGE_COUNT = './/span//text()'\n",
    "            raw_language_type = language.xpath(XPATH_LANGUAGE_TYPE)\n",
    "            raw_language_count = language.xpath(XPATH_LANGUAGE_COUNT)\n",
    "            cleaned_language_type = ''.join(raw_language_type).replace('\\n','').split(' ')\n",
    "            cleaned_language_type = cleaned_language_type[0]\n",
    "            cleaned_language_count = ''.join(raw_language_count).replace('\\n','')\n",
    "            language_list.append(cleaned_language_type)\n",
    "        language_list = language_list[1:]\n",
    "\n",
    "\n",
    "        data = {'name':name,\n",
    "\t\t\t\t'rank':rank,\n",
    "\t\t\t\t'rating':hotel_rating,\n",
    "                'review_count':review_count,\n",
    "                'latitude':latitude,\n",
    "                'longitude':longitude,\n",
    "#                 'official_description':official_description,\n",
    "                  'travelers':travelers_list,\n",
    "                  'times of year':times_list,\n",
    "                  'languages':language_list\n",
    "#                  'details':details\n",
    "\t    }\n",
    "        restaurants.append(data)\n",
    "        \n",
    "        \n",
    "#    columns = ['property_title', 'rank', 'rating', 'review_count', 'location', 'official_description', 'travelers', 'times', 'langauges']\n",
    "    df = pd.DataFrame(restaurants)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "input_file = open('restaurants.txt', 'r')\n",
    "scraped_data = parse(input_file)\n",
    "scraped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('restaurants_details.csv', 'w') as csvfile:\n",
    "    scraped_data.to_csv(csvfile, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
